/*
 * This file is part of the UCB release of Plan 9. It is subject to the license
 * terms in the LICENSE file found in the top-level directory of this
 * distribution and at http://akaros.cs.berkeley.edu/files/Plan9License. No
 * part of the UCB release of Plan 9, including this file, may be copied,
 * modified, propagated, or distributed except according to the terms contained
 * in the LICENSE file.
 */

//#include "u.h"
//#include "../port/lib.h"
//#include "mem.h"
//#include "dat.h"
//#include "fns.h"

// Simple slab allocator
// Implemented:
//  - ?
// Todo:
//  - kmemcachecreate
//  - kmemcachedestroy
//  - kmemcachealloc
//  - kmemcachefree
//  - kmemcache(shrink|reap)
//  - kmalloc
//  - kfree
//  - Expose slabs, slab stats in fs
//
// Initially there will be no magazines and no vmem.  It'll be implemented
// on top of qmalloc.  Just need kmemcachecreate, kmalloc and kfree for now.
// Caches should collect stats.  Can initially collect per-cache stats while
// really using qmalloc.

#undef DBG
#define DBG(...)				\
	do {					\
		if(0)				\
			print(__VA_ARGS__);	\
	} while(0)

typedef struct KMemCache KMemCache;
typedef struct KSlabSmallCtl KSlabSmallCtl;
typedef struct KSlabSmallBufCtl KSlabSmallBufCtl;
typedef struct KSlabBuf8 KSlabBuf8;
typedef struct KSlab8 KSlab8;

enum {
	// TODO these should be autogenerated
	KMallocSlab8NumBufs = 510,
};

struct KSlabSmallCtl {
	u32	numfree;
	u8	_padding[4];
	void	*nextfree;
};
static_assert(sizeof(KSlabSmallCtl) == 16, "not expected size");

struct KSlabSmallBufCtl {
	KSlabBuf8 *nextfree;
};
static_assert(sizeof(KSlabSmallBufCtl) == 8, "not expected size");

// TODO maybe this should all be generated?
struct KSlabBuf8 {
	union {
		char data[8];
		// TODO push bufctl to end for larger objsizes
		KSlabSmallBufCtl bufctl;
	};
};
static_assert(sizeof(KSlabBuf8) == 8, "not expected size");
struct KSlab8 {
	KSlabBuf8	bufs[KMallocSlab8NumBufs];
	KSlabSmallCtl	ctl;
};
static_assert(sizeof(KSlab8) == PGSZ, "not expected size");

struct KMemCache {
	char	*name;
	u32	objsize;
	void	*slab;
	Lock	lock;
};

/*static KMemCache cachecache = {
	.name		= "kmemcachecache",
	.objsize	= sizeof(KMemCache),
	.slab		= nil,
};*/

alignas(4096) static KSlab8 slab8;
static KMemCache kmalloccaches[] = {
	{ .name = "kmemcache8", .objsize = 8, .slab = &slab8 },
};


// kmemcacheinit initialises the core caches for kmalloc
void
kmemcacheinit()
{
	// Small object caches (up to nearly 512 bytes depending on size of
	// slab data - exact size TBD)
	// Simple layout, initial slabs statically allocated
	for (int i = 0; i < KMallocSlab8NumBufs-1; i++) {
		slab8.bufs[i].bufctl.nextfree = &slab8.bufs[i+1];
	}
	slab8.bufs[KMallocSlab8NumBufs-1].bufctl.nextfree = nil;
	slab8.ctl.numfree = KMallocSlab8NumBufs;
	slab8.ctl.nextfree = &slab8.bufs[0];

	//kmalloccaches[0] = kmemcachecreate("kmemcache8", 8);
	//kmalloccaches[1] = kmemcachecreate("kmemcache16", 16);
	//kmalloccaches[2] = kmemcachecreate("kmemcache32", 32);
	//kmalloccaches[3] = kmemcachecreate("kmemcache64", 64);
	//kmalloccaches[4] = kmemcachecreate("kmemcache64", 128);
	//kmalloccaches[5] = kmemcachecreate("kmemcache64", 256);
	//kmalloccaches[0] = kmemcachecreate("kmemcache64", 64);
	//kmalloccaches[0] = kmemcachecreate("kmemcache64", 64);
	//kmalloccaches[1] = kmemcachecreate("kmemcache305", 305);
	//kmalloccaches[2] = kmemcachecreate("kmemcache602", 602);
	//kmalloccaches[3] = kmemcachecreate("kmemcache899", 899);
	//kmalloccaches[4] = kmemcachecreate("kmemcache1196", 1196);
	//kmalloccaches[5] = kmemcachecreate("kmemcache1493", 1493);
	//kmalloccaches[6] = kmemcachecreate("kmemcache1790", 1790);
	// TODO handle larger buffer sizes
	//kmalloccaches[7] = kmemcachecreate("kmemcache2087", 2087);
	//kmalloccaches[8] = kmemcachecreate("kmemcache2384", 2384);
	//kmalloccaches[9] = kmemcachecreate("kmemcache2681", 2681);
	//kmalloccaches[10] = kmemcachecreate("kmemcache2978", 2978);
	//kmalloccaches[11] = kmemcachecreate("kmemcache3275", 3275);
	//kmalloccaches[12] = kmemcachecreate("kmemcache3572", 3572);
	//kmalloccaches[13] = kmemcachecreate("kmemcache3869", 3869);
	//kmalloccaches[14] = kmemcachecreate("kmemcache4166", 4166);
	//kmalloccaches[15] = kmemcachecreate("kmemcache4463", 4463);
	//kmalloccaches[16] = kmemcachecreate("kmemcache4760", 4760);
	//kmalloccaches[17] = kmemcachecreate("kmemcache5057", 5057);
	//kmalloccaches[18] = kmemcachecreate("kmemcache5354", 5354);
	//kmalloccaches[19] = kmemcachecreate("kmemcache5651", 5651);
	//kmalloccaches[20] = kmemcachecreate("kmemcache5948", 5948);
	//kmalloccaches[21] = kmemcachecreate("kmemcache6245", 6245);
	//kmalloccaches[22] = kmemcachecreate("kmemcache6542", 6542);
	//kmalloccaches[23] = kmemcachecreate("kmemcache6839", 6839);
	//kmalloccaches[24] = kmemcachecreate("kmemcache7136", 7136);
	//kmalloccaches[25] = kmemcachecreate("kmemcache7433", 7433);
	//kmalloccaches[26] = kmemcachecreate("kmemcache7730", 7730);
	//kmalloccaches[27] = kmemcachecreate("kmemcache8027", 8027);
	//kmalloccaches[28] = kmemcachecreate("kmemcache8324", 8324);
	//kmalloccaches[29] = kmemcachecreate("kmemcache8621", 8621);
	//kmalloccaches[30] = kmemcachecreate("kmemcache8918", 8918);
	//kmalloccaches[31] = kmemcachecreate("kmemcache9216", 9216);
}

// kmemcachecreate creates a new cache for a particular object size.
// TODO
// - colouring
// - constructor
// - flags
KMemCache *
kmemcachecreate(const char *name, u32 objsize)
{
	return nil;
}

// kmemcachedestroy frees an entire cache, returning the memory to the system.
void kmemcachedestroy(KMemCache *cache)
{
}

// kmemcacheinslab returns true if obj is in the given slab.
// Relies on the slab being a page in size.
static int
kmemcacheinslab(void *slab, void *obj)
{
	// TODO assert it's a valid position
	return (obj >= slab && obj < slab + PGSZ);
}

// kmemcachefindslab looks up a cache by name.  This is a slow internal function for testing.
static KMemCache *
kmemcachefindslab(void *obj)
{
	int numcaches = nelem(kmalloccaches);
	for (int i = 0; i < numcaches; i++) {
		// TODO handle more than one slab
		if (kmemcacheinslab(kmalloccaches[i].slab, obj)) {
			return &kmalloccaches[i];
		}
	}
	return nil;
}

// getslabsmallctl will return the ctl struct for the given slab
static KSlabSmallCtl *
getslabsmallctl(void *slab)
{
	return (KSlabSmallCtl*)(ROUNDDN((uintptr)slab, PGSZ) + PGSZ - sizeof(KSlabSmallCtl));
}

// kmemcachealloc allocates an object from the given cache.
// TODO
// - flags
void *
kmemcachealloc(KMemCache *cache)
{
	lock(&cache->lock);

	// TODO allocate more slabs if necessary
	// TODO Check it's a small slab
	KSlabSmallCtl *slabctl = getslabsmallctl(cache->slab);
	if (slabctl->numfree == 0) {
		unlock(&cache->lock);
		panic("kmemcachealloc: slab full, unable to create new slab (%s)", cache->name);
		return nil;
	}

	// Slab has space
	KSlabBuf8 *buf = (KSlabBuf8*)slabctl->nextfree;
	slabctl->nextfree = (KSlabBuf8*)(buf->bufctl.nextfree);
	slabctl->numfree--;
	unlock(&cache->lock);

	return buf;
}

// kmemcachefree frees a cache object back onto the cache.
void
kmemcachefree(KMemCache *cache, void *obj)
{
	lock(&cache->lock);

	// TODO different sized slabs
	// Add to freelist
	KSlabBuf8 *slabbuf = (KSlabBuf8*)obj;
	KSlabSmallCtl *slabctl = getslabsmallctl(cache->slab);
	slabctl->numfree++;
	slabbuf->bufctl.nextfree = slabctl->nextfree;
	slabctl->nextfree = obj;

	unlock(&cache->lock);
}

// kmalloc is an equivalent to malloc, but allocates from the cache.  It will
// use the cache with the nearest larger object size.  If no cache is large
// enough, it's allocate directly from pages.
void *
kmalloc(usize size)
{
	int numcaches = nelem(kmalloccaches);
	if (size > kmalloccaches[numcaches-1].objsize) {
		// Too big for caches, use page supplier?
		panic("kmalloc: too big (%llu)", size);
		return nil;
	}

	// TODO binary search for best size?
	for (int i = 0; i < numcaches; i++) {
		if (kmalloccaches[i].objsize >= size) {
			DBG("kmalloc: found cache %s\n", kmalloccaches[i].name);
			return kmemcachealloc(&kmalloccaches[i]);
		}
	}

	panic("kmalloc: no cache found for size %llu", size);
	return nil;
}

// kfree is an equivalent to free, but for memory that was allocated via kmalloc.
void
kfree(void *obj)
{
	// Scan the kmalloc slabs.  If the address isn't in these slabs, assume
	// it's been allocated as a large object.  I guess we can imply the
	// location of the slab ctl at the end of the page and use that to free.

	int numcaches = nelem(kmalloccaches);
	for (int i = 0; i < numcaches; i++) {
		// TODO handle more than one slab
		if (kmemcacheinslab(kmalloccaches[i].slab, obj)) {
			kmemcachefree(&kmalloccaches[i], obj);
			return;
		}
	}

	panic("kfree: can't find cache to free %p", obj);
}
